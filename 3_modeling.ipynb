{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook aims to evaluate the performance of various classification algorithms, fine-tune their hyperparameters, and select the best-performing model. Given the imbalanced nature of the dataset, class weighting (`class_weight='balanced'`) will be applied to enhance model performance.\n",
    "\n",
    "The algorithms to be evaluated include:\n",
    "\n",
    "- Logistic Regression\n",
    "- Decision Tree\n",
    "\n",
    "Each model will undergo:\n",
    "1. Baseline training with default hyperparameters.\n",
    "2. Hyperparameter tuning to optimize performance.\n",
    "3. Validation using metrics such as AUC to identify overfitting and select the final model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Note:\n",
    "**(Strongly correlated features)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During initial tests, we observed the model achieved high performance due to features strongly correlated with the target variable, such as economic participation and hours worked, reflecting real-world factors influencing school dropout rates. To better evaluate model performance and for illustrative purposes in this exercise, we will exclude the most predictive features, allowing us to practice model selection, training, and tuning without their dominant influence. The following cells will demonstrate this condition and make the aforementioned adjustments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# Suppress ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression with default parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('G:\\Mi unidad\\###_ ML Zoomcamp 2024\\enape_post_eda.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split dataset (60/20/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=1)\n",
    "\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "y_train = df_train.dropout.values\n",
    "y_val = df_val.dropout.values\n",
    "y_test = df_test.dropout.values\n",
    "\n",
    "del df_train['dropout']\n",
    "del df_val['dropout']\n",
    "del df_test['dropout']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11983, 41)\n",
      "(3995, 41)\n",
      "(3995, 41)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(df_val.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=1000)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "train_dict = df_train.to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dict)\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9987484355444305)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dict = df_val.to_dict(orient='records')\n",
    "X_val = dv.transform(val_dict)\n",
    "\n",
    "y_pred = model.predict_proba(X_val)[:, 1]\n",
    "dropout_prediction = (y_pred >= 0.5)\n",
    "(y_val == dropout_prediction).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3907\n",
      "           1       1.00      0.94      0.97        88\n",
      "\n",
      "    accuracy                           1.00      3995\n",
      "   macro avg       1.00      0.97      0.99      3995\n",
      "weighted avg       1.00      1.00      1.00      3995\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_val, dropout_prediction)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.972)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_val,dropout_prediction).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that our model is overfitting, we'll check with the test split and see how it handles new data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9987484355444305)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict = df_test.to_dict(orient='records')\n",
    "X_test = dv.transform(test_dict)\n",
    "\n",
    "y_pred = model.predict_proba(X_test)[:, 1]\n",
    "dropout_prediction = (y_pred >= 0.5)\n",
    "(y_test == dropout_prediction).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3931\n",
      "           1       0.98      0.94      0.96        64\n",
      "\n",
      "    accuracy                           1.00      3995\n",
      "   macro avg       0.99      0.97      0.98      3995\n",
      "weighted avg       1.00      1.00      1.00      3995\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test, dropout_prediction)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.969)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test,dropout_prediction).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model performs well on new data, indicating that it is generalizing effectively. Therefore, we can proceed with a cross-validation exercise.\n",
    "\n",
    "Additionally, we know (as stated in the [Corelation Analysis with the Target Variable](https://github.com/Maxkaizo/---_-ML-Zoomcamp-2024/blob/main/2_eda.ipynb)) that certain features, such as economic participation, economic consequences, and work hours, have a strong influence on dropout rates. To further illustrate the impact of feature selection, we will remove some of these features in the next steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99833125 0.99666249 0.99791406 0.99791319 0.99958264]\n",
      "Cross-Validation Accuracy (mean): 0.9980807255591471\n",
      "Cross-Validation Accuracy (std): 0.0009365603198218517\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "mean_accuracy = scores.mean()\n",
    "std_accuracy = np.std(scores)\n",
    "\n",
    "print(scores)\n",
    "print(\"Cross-Validation Accuracy (mean):\", mean_accuracy)\n",
    "print(\"Cross-Validation Accuracy (std):\", std_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base Model Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model performs exceptionally well, mostly due to the presence of highly correlated features. After testing it with cross-validation and new data, we can conclude that it generalizes effectively. This aligns with the real-world scenario, where it is intuitive to expect that students with excessive work hours, high economic participation, and significant economic consequences are more likely to drop out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature exclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated before, we'll exclude some features in order to run the model's selection and fine tunning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('G:\\Mi unidad\\###_ ML Zoomcamp 2024\\enape_post_eda.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\n",
    "    'em_hw_projects',\n",
    "    'em_tests',\n",
    "    #'economic_participation',\n",
    "    #'economic_consequences'\n",
    "    ] \n",
    "df_full_train = df_full_train.drop(columns=columns_to_drop, axis=1)\n",
    "df_train = df_train.drop(columns=columns_to_drop, axis=1)\n",
    "df_val = df_val.drop(columns=columns_to_drop, axis=1)\n",
    "df_test = df_test.drop(columns=columns_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11983, 39)\n",
      "(3995, 39)\n",
      "(3995, 39)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(df_val.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Functions (Train, Predict, Evaluation Metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(df_train, y_train, C=1.0,cw=None):\n",
    "    dict = df_train.to_dict(orient='records')\n",
    "\n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    X_train = dv.fit_transform(dict)\n",
    "\n",
    "    model = LogisticRegression(C=C, max_iter=1000,class_weight=cw)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    return dv, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(df, dv, model,t):\n",
    "    dict = df.to_dict(orient='records')\n",
    "\n",
    "    X = dv.transform(dict)\n",
    "    y_pred = model.predict_proba(X)[:, 1]\n",
    "    dropout_prediction = (y_pred >= t)\n",
    "\n",
    "    return y_pred, dropout_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(y, dropout_prediction):\n",
    "\n",
    "    gral_accuracy = (y == dropout_prediction).mean()\n",
    "    report = classification_report(y, dropout_prediction, output_dict=True)\n",
    "    auc = roc_auc_score(y, dropout_prediction).round(3)\n",
    "    \n",
    "    # Filtrar solo la clase 1 del reporte\n",
    "    class_1_report = report[\"1\"]\n",
    "    \n",
    "    metrics_dict = {\n",
    "        \"gral_accuracy\": gral_accuracy,\n",
    "        \"class_1_report\": class_1_report,\n",
    "        \"auc\": auc\n",
    "    }\n",
    "    \n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base (Poor) Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gral_accuracy': np.float64(0.9799749687108886),\n",
       " 'class_1_report': {'precision': 0.6666666666666666,\n",
       "  'recall': 0.18181818181818182,\n",
       "  'f1-score': 0.2857142857142857,\n",
       "  'support': 88.0},\n",
       " 'auc': np.float64(0.59)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv, model = train(df_train, y_train, C=1.0,cw=None)\n",
    "y_pred, dropout_prediction = predict(df_val, dv, model,t=0.5)\n",
    "eval_metrics(y_val, dropout_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated before, this model shows a poor performance. It has an apparently good accuracy score, but our main metric is recall and its to low, also our auc shows barely a better performance than a random model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Weight Balancing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first improvement is to apply balanced weights, this technique deals with imbalance by applying a higher ponderation to the minority class, in this case the dropout class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gral_accuracy': np.float64(0.8578222778473091),\n",
       " 'class_1_report': {'precision': 0.1261682242990654,\n",
       "  'recall': 0.9204545454545454,\n",
       "  'f1-score': 0.2219178082191781,\n",
       "  'support': 88.0},\n",
       " 'auc': np.float64(0.888)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv, model = train(df_train, y_train, C=1.0,cw=\"balanced\")\n",
    "y_pred, dropout_prediction = predict(df_val, dv, model,t=0.5)\n",
    "eval_metrics(y_val, dropout_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this change, we see a huge improvement on recall and auc, but also a huge decrease on precision, we'll keep tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the model shows way better recall and auc, but now it shows poor precision, so now we'll try to find a better balance by:\n",
    "- Trying some regularization values\n",
    "- Adjusting the decision threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_values = [1.0, 0.01, 0.001, 0.0001, 0.00001]\n",
    "thresholds = [0.3, 0.5, 0.7, 0.8, 0.9]\n",
    "\n",
    "eval_metrics_dict = []\n",
    "\n",
    "for c in c_values:\n",
    "    for t in thresholds:\n",
    "        dv, model = train(df_train, y_train, C=c, cw=\"balanced\")\n",
    "        y_pred, dropout_prediction = predict(df_val, dv, model,t=t)\n",
    "        \n",
    "        # Evalúa las métricas\n",
    "        eval_metrics_result = eval_metrics(y_val, dropout_prediction)\n",
    "        \n",
    "        # Almacena los resultados en el diccionario\n",
    "        eval_metrics_dict.append({\n",
    "            \"C\": c,\n",
    "            \"Threshold\": t,\n",
    "            \"result\": eval_metrics_result\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for item in eval_metrics_dict:\n",
    "    c_value = item['C']\n",
    "    threshold = item['Threshold']\n",
    "    gral_accuracy = item['result']['gral_accuracy']\n",
    "    auc = item['result']['auc']\n",
    "    class_1_report = item['result']['class_1_report']\n",
    "    rows.append({\n",
    "        \"C\": c_value,\n",
    "        \"Threshold\": threshold,\n",
    "        \"gral_accuracy\": gral_accuracy,\n",
    "        \"auc\": auc,\n",
    "        \"precision\": class_1_report['precision'],\n",
    "        \"recall\": class_1_report['recall'],\n",
    "        \"f1_score\": class_1_report['f1-score'],\n",
    "        \"support\": class_1_report['support']\n",
    "    })\n",
    "\n",
    "# Crear el DataFrame\n",
    "df_results = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>Threshold</th>\n",
       "      <th>gral_accuracy</th>\n",
       "      <th>auc</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.915394</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.292887</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.857822</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.126168</td>\n",
       "      <td>0.920455</td>\n",
       "      <td>0.221918</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.848561</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.110106</td>\n",
       "      <td>0.829545</td>\n",
       "      <td>0.194407</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.831039</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.097394</td>\n",
       "      <td>0.806818</td>\n",
       "      <td>0.173807</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.796496</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.093154</td>\n",
       "      <td>0.943182</td>\n",
       "      <td>0.169561</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        C  Threshold  gral_accuracy    auc  precision    recall  f1_score  \\\n",
       "2   1.000        0.7       0.915394  0.857   0.179487  0.795455  0.292887   \n",
       "1   1.000        0.5       0.857822  0.888   0.126168  0.920455  0.221918   \n",
       "6   0.010        0.5       0.848561  0.839   0.110106  0.829545  0.194407   \n",
       "11  0.001        0.5       0.831039  0.819   0.097394  0.806818  0.173807   \n",
       "0   1.000        0.3       0.796496  0.868   0.093154  0.943182  0.169561   \n",
       "\n",
       "    support  \n",
       "2      88.0  \n",
       "1      88.0  \n",
       "6      88.0  \n",
       "11     88.0  \n",
       "0      88.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results[df_results['recall'] > 0.75].sort_values(by='f1_score', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll select the top 2 combinations as candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll try another technique for dealing with our imbalanced dataset, this one is called SMOTE (Synthetic Minority Oversampling Technique), which is a method that generates synthetic samples for the minority class. It works by interpolating new samples between existing minority class instances, rather than simply duplicating them, which helps create a more balanced dataset and improves model performance without overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_wsmote(df_train, y_train, C=1.0,cw=None):\n",
    "    dict = df_train.to_dict(orient='records')\n",
    "\n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    X_train = dv.fit_transform(dict)\n",
    "    \n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    model = LogisticRegression(C=C, max_iter=1000,class_weight=cw)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    return dv, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_values = [1.0, 0.01, 0.001, 0.0001, 0.00001]\n",
    "thresholds = [0.3, 0.5, 0.7, 0.8, 0.9]\n",
    "\n",
    "eval_metrics_dict = []\n",
    "\n",
    "for c in c_values:\n",
    "    for t in thresholds:\n",
    "        dv, model = train_wsmote(df_train, y_train, C=c, cw=None) # As we're using SMOTE, in this case we won't use class weights\n",
    "        y_pred, dropout_prediction = predict(df_val, dv, model,t=t)\n",
    "        \n",
    "        eval_metrics_result = eval_metrics(y_val, dropout_prediction)\n",
    "        \n",
    "        eval_metrics_dict.append({\n",
    "            \"C\": c,\n",
    "            \"Threshold\": t,\n",
    "            \"result\": eval_metrics_result\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for item in eval_metrics_dict:\n",
    "    c_value = item['C']\n",
    "    threshold = item['Threshold']\n",
    "    gral_accuracy = item['result']['gral_accuracy']\n",
    "    auc = item['result']['auc']\n",
    "    class_1_report = item['result']['class_1_report']\n",
    "    rows.append({\n",
    "        \"C\": c_value,\n",
    "        \"Threshold\": threshold,\n",
    "        \"gral_accuracy\": gral_accuracy,\n",
    "        \"auc\": auc,\n",
    "        \"precision\": class_1_report['precision'],\n",
    "        \"recall\": class_1_report['recall'],\n",
    "        \"f1_score\": class_1_report['f1-score'],\n",
    "        \"support\": class_1_report['support']\n",
    "    })\n",
    "\n",
    "df_results_wsmote = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>Threshold</th>\n",
       "      <th>gral_accuracy</th>\n",
       "      <th>auc</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.915394</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.292887</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.857822</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.126168</td>\n",
       "      <td>0.920455</td>\n",
       "      <td>0.221918</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.848561</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.110106</td>\n",
       "      <td>0.829545</td>\n",
       "      <td>0.194407</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.831039</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.097394</td>\n",
       "      <td>0.806818</td>\n",
       "      <td>0.173807</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.796496</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.093154</td>\n",
       "      <td>0.943182</td>\n",
       "      <td>0.169561</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        C  Threshold  gral_accuracy    auc  precision    recall  f1_score  \\\n",
       "2   1.000        0.7       0.915394  0.857   0.179487  0.795455  0.292887   \n",
       "1   1.000        0.5       0.857822  0.888   0.126168  0.920455  0.221918   \n",
       "6   0.010        0.5       0.848561  0.839   0.110106  0.829545  0.194407   \n",
       "11  0.001        0.5       0.831039  0.819   0.097394  0.806818  0.173807   \n",
       "0   1.000        0.3       0.796496  0.868   0.093154  0.943182  0.169561   \n",
       "\n",
       "    support  \n",
       "2      88.0  \n",
       "1      88.0  \n",
       "6      88.0  \n",
       "11     88.0  \n",
       "0      88.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results[df_results['recall'] > 0.75].sort_values(by='f1_score', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>Threshold</th>\n",
       "      <th>gral_accuracy</th>\n",
       "      <th>auc</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.922904</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.872591</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.128748</td>\n",
       "      <td>0.829545</td>\n",
       "      <td>0.222901</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866583</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.124789</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>0.217327</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.850563</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.109063</td>\n",
       "      <td>0.806818</td>\n",
       "      <td>0.192152</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.821777</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.104061</td>\n",
       "      <td>0.931818</td>\n",
       "      <td>0.187215</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        C  Threshold  gral_accuracy    auc  precision    recall  f1_score  \\\n",
       "2   1.000        0.7       0.922904  0.861   0.194444  0.795455  0.312500   \n",
       "1   1.000        0.5       0.872591  0.852   0.128748  0.829545  0.222901   \n",
       "6   0.010        0.5       0.866583  0.854   0.124789  0.840909  0.217327   \n",
       "11  0.001        0.5       0.850563  0.829   0.109063  0.806818  0.192152   \n",
       "0   1.000        0.3       0.821777  0.876   0.104061  0.931818  0.187215   \n",
       "\n",
       "    support  \n",
       "2      88.0  \n",
       "1      88.0  \n",
       "6      88.0  \n",
       "11     88.0  \n",
       "0      88.0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_wsmote[df_results_wsmote['recall'] > 0.75].sort_values(by='f1_score', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This indicates that while SMOTE helps the model to be more precise in its predictions for the minority class (fewer false positives)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the Decision Tree We'll try selecting this hyperparameters:\n",
    "\n",
    "- Depth\n",
    "- Minimium samples per leaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import additional Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dicts = df_train.to_dict(orient='records')\n",
    "\n",
    "dv = DictVectorizer(sparse=False)\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "val_dicts = df_val.to_dict(orient='records')\n",
    "X_val = dv.transform(val_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll iterate over several max depths and min samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = [1, 2, 3, 4, 5, 6, 10, 15, 20, None]\n",
    "samples = [1, 5, 10, 15, 20, 500, 100, 200]\n",
    "dt_metrics_dict = []\n",
    "\n",
    "for depth in depths:\n",
    "    for s in samples:\n",
    "        dt = DecisionTreeClassifier(max_depth=depth,class_weight=\"balanced\",min_samples_leaf=s)\n",
    "        dt.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = dt.predict_proba(X_val)[:, 1]\n",
    "        dropout_prediction = (y_pred >= 0.5)\n",
    "        \n",
    "        gral_accuracy = (y_val == dropout_prediction).mean()\n",
    "        report = classification_report(y_val, dropout_prediction, output_dict=True)\n",
    "        auc = roc_auc_score(y_val, dropout_prediction)\n",
    "        \n",
    "        class_1_report = report[\"1\"]\n",
    "        \n",
    "        dt_metrics_dict.append({\n",
    "            \"depth\": depth,\n",
    "            \"min_samples\": s,\n",
    "            \"gral_accuracy\": gral_accuracy,\n",
    "            \"precision\": class_1_report['precision'],\n",
    "            \"recall\": class_1_report['recall'],\n",
    "            \"f1_score\": class_1_report['f1-score'],\n",
    "            \"support\": class_1_report['support'],\n",
    "            \"auc\": auc\n",
    "        })\n",
    "\n",
    "dt_results = pd.DataFrame(dt_metrics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>min_samples</th>\n",
       "      <th>gral_accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>support</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.875594</td>\n",
       "      <td>0.130199</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.224649</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.847535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.875594</td>\n",
       "      <td>0.130199</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.224649</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.847535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.875594</td>\n",
       "      <td>0.130199</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.224649</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.847535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.875594</td>\n",
       "      <td>0.130199</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.224649</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.847535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3.0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.875594</td>\n",
       "      <td>0.130199</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.224649</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.847535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    depth  min_samples  gral_accuracy  precision    recall  f1_score  support  \\\n",
       "16    3.0            1       0.875594   0.130199  0.818182  0.224649     88.0   \n",
       "18    3.0           10       0.875594   0.130199  0.818182  0.224649     88.0   \n",
       "17    3.0            5       0.875594   0.130199  0.818182  0.224649     88.0   \n",
       "19    3.0           15       0.875594   0.130199  0.818182  0.224649     88.0   \n",
       "20    3.0           20       0.875594   0.130199  0.818182  0.224649     88.0   \n",
       "\n",
       "         auc  \n",
       "16  0.847535  \n",
       "18  0.847535  \n",
       "17  0.847535  \n",
       "19  0.847535  \n",
       "20  0.847535  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_results[dt_results['recall'] > 0.75].sort_values(by='precision', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>min_samples</th>\n",
       "      <th>gral_accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>support</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.875594</td>\n",
       "      <td>0.130199</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.224649</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.847535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.875594</td>\n",
       "      <td>0.130199</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.224649</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.847535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.875594</td>\n",
       "      <td>0.130199</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.224649</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.847535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.875594</td>\n",
       "      <td>0.130199</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.224649</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.847535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3.0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.875594</td>\n",
       "      <td>0.130199</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.224649</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.847535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    depth  min_samples  gral_accuracy  precision    recall  f1_score  support  \\\n",
       "16    3.0            1       0.875594   0.130199  0.818182  0.224649     88.0   \n",
       "18    3.0           10       0.875594   0.130199  0.818182  0.224649     88.0   \n",
       "17    3.0            5       0.875594   0.130199  0.818182  0.224649     88.0   \n",
       "19    3.0           15       0.875594   0.130199  0.818182  0.224649     88.0   \n",
       "20    3.0           20       0.875594   0.130199  0.818182  0.224649     88.0   \n",
       "\n",
       "         auc  \n",
       "16  0.847535  \n",
       "18  0.847535  \n",
       "17  0.847535  \n",
       "19  0.847535  \n",
       "20  0.847535  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_results[dt_results['recall'] > 0.75].sort_values(by='f1_score', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the Decision Tree We'll try selecting this hyperparameters:\n",
    "\n",
    "- Number of estimators\n",
    "- Trees Depth\n",
    "- Minimium samples per leaf- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 150, 200]\n",
    "depths = [None, 5, 10, 15, 20, 25, 30]\n",
    "samples = [1, 5, 10, 15, 20, 500, 100, 200]\n",
    "rf_metrics_dict = []\n",
    "\n",
    "for n in estimators:\n",
    "    for d in depths:\n",
    "        for s in samples:\n",
    "            rf = RandomForestClassifier(n_estimators=n, max_depth=d, min_samples_leaf=s, class_weight='balanced', random_state=1)\n",
    "            \n",
    "            rf.fit(X_train, y_train)\n",
    "            \n",
    "            y_pred = rf.predict_proba(X_val)[:, 1]\n",
    "            dropout_prediction = (y_pred >= 0.5)\n",
    "            \n",
    "            gral_accuracy = (y_val == dropout_prediction).mean()\n",
    "            report = classification_report(y_val, dropout_prediction, output_dict=True)\n",
    "            auc = roc_auc_score(y_val, dropout_prediction)\n",
    "            \n",
    "            class_1_report = report[\"1\"]\n",
    "            \n",
    "            rf_metrics_dict.append({\n",
    "                \"n_estimators\": n,\n",
    "                \"max_depth\": d,\n",
    "                \"min_samples\": s,\n",
    "                \"gral_accuracy\": gral_accuracy,\n",
    "                \"precision\": class_1_report['precision'],\n",
    "                \"recall\": class_1_report['recall'],\n",
    "                \"f1_score\": class_1_report['f1-score'],\n",
    "                \"support\": class_1_report['support'],\n",
    "                \"auc\": auc\n",
    "            })\n",
    "\n",
    "rf_results = pd.DataFrame(rf_metrics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples</th>\n",
       "      <th>gral_accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>support</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>90</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.902879</td>\n",
       "      <td>0.159091</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.265152</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.850376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>100</td>\n",
       "      <td>25.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.902378</td>\n",
       "      <td>0.158371</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.264151</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.850120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>100</td>\n",
       "      <td>30.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.902378</td>\n",
       "      <td>0.158371</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.264151</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.850120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>100</td>\n",
       "      <td>20.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.902378</td>\n",
       "      <td>0.158371</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.264151</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.850120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>0.902378</td>\n",
       "      <td>0.158371</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.264151</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.850120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     n_estimators  max_depth  min_samples  gral_accuracy  precision    recall  \\\n",
       "470            90       10.0          100       0.902879   0.159091  0.795455   \n",
       "550           100       25.0          100       0.902378   0.158371  0.795455   \n",
       "558           100       30.0          100       0.902378   0.158371  0.795455   \n",
       "542           100       20.0          100       0.902378   0.158371  0.795455   \n",
       "510           100        NaN          100       0.902378   0.158371  0.795455   \n",
       "\n",
       "     f1_score  support       auc  \n",
       "470  0.265152     88.0  0.850376  \n",
       "550  0.264151     88.0  0.850120  \n",
       "558  0.264151     88.0  0.850120  \n",
       "542  0.264151     88.0  0.850120  \n",
       "510  0.264151     88.0  0.850120  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_results[rf_results['recall'] > 0.75].sort_values(by='f1_score', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples</th>\n",
       "      <th>gral_accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>support</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>90</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.902879</td>\n",
       "      <td>0.159091</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.265152</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.850376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>100</td>\n",
       "      <td>30.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.902378</td>\n",
       "      <td>0.158371</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.264151</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.850120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>100</td>\n",
       "      <td>20.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.902378</td>\n",
       "      <td>0.158371</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.264151</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.850120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>0.902378</td>\n",
       "      <td>0.158371</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.264151</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.850120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>100</td>\n",
       "      <td>15.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.902378</td>\n",
       "      <td>0.158371</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.264151</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.850120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     n_estimators  max_depth  min_samples  gral_accuracy  precision    recall  \\\n",
       "470            90       10.0          100       0.902879   0.159091  0.795455   \n",
       "558           100       30.0          100       0.902378   0.158371  0.795455   \n",
       "542           100       20.0          100       0.902378   0.158371  0.795455   \n",
       "510           100        NaN          100       0.902378   0.158371  0.795455   \n",
       "534           100       15.0          100       0.902378   0.158371  0.795455   \n",
       "\n",
       "     f1_score  support       auc  \n",
       "470  0.265152     88.0  0.850376  \n",
       "558  0.264151     88.0  0.850120  \n",
       "542  0.264151     88.0  0.850120  \n",
       "510  0.264151     88.0  0.850120  \n",
       "534  0.264151     88.0  0.850120  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_results[rf_results['recall'] > 0.75].sort_values(by='precision', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll compare our best performing models and select one based on recall, but looking for a balance with f1-score and balance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with class weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>Threshold</th>\n",
       "      <th>gral_accuracy</th>\n",
       "      <th>auc</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.915394</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.292887</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.857822</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.126168</td>\n",
       "      <td>0.920455</td>\n",
       "      <td>0.221918</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.848561</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.110106</td>\n",
       "      <td>0.829545</td>\n",
       "      <td>0.194407</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      C  Threshold  gral_accuracy    auc  precision    recall  f1_score  \\\n",
       "2  1.00        0.7       0.915394  0.857   0.179487  0.795455  0.292887   \n",
       "1  1.00        0.5       0.857822  0.888   0.126168  0.920455  0.221918   \n",
       "6  0.01        0.5       0.848561  0.839   0.110106  0.829545  0.194407   \n",
       "\n",
       "   support  \n",
       "2     88.0  \n",
       "1     88.0  \n",
       "6     88.0  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results[df_results['recall'] > 0.75].sort_values(by='f1_score', ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>Threshold</th>\n",
       "      <th>gral_accuracy</th>\n",
       "      <th>auc</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.922904</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.872591</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.128748</td>\n",
       "      <td>0.829545</td>\n",
       "      <td>0.222901</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866583</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.124789</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>0.217327</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      C  Threshold  gral_accuracy    auc  precision    recall  f1_score  \\\n",
       "2  1.00        0.7       0.922904  0.861   0.194444  0.795455  0.312500   \n",
       "1  1.00        0.5       0.872591  0.852   0.128748  0.829545  0.222901   \n",
       "6  0.01        0.5       0.866583  0.854   0.124789  0.840909  0.217327   \n",
       "\n",
       "   support  \n",
       "2     88.0  \n",
       "1     88.0  \n",
       "6     88.0  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_wsmote[df_results_wsmote['recall'] > 0.75].sort_values(by='f1_score', ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>min_samples</th>\n",
       "      <th>gral_accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>support</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.875594</td>\n",
       "      <td>0.130199</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.224649</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.847535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.875594</td>\n",
       "      <td>0.130199</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.224649</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.847535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.875594</td>\n",
       "      <td>0.130199</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.224649</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.847535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    depth  min_samples  gral_accuracy  precision    recall  f1_score  support  \\\n",
       "16    3.0            1       0.875594   0.130199  0.818182  0.224649     88.0   \n",
       "18    3.0           10       0.875594   0.130199  0.818182  0.224649     88.0   \n",
       "17    3.0            5       0.875594   0.130199  0.818182  0.224649     88.0   \n",
       "\n",
       "         auc  \n",
       "16  0.847535  \n",
       "18  0.847535  \n",
       "17  0.847535  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_results[dt_results['recall'] > 0.75].sort_values(by='f1_score', ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples</th>\n",
       "      <th>gral_accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>support</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>90</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.902879</td>\n",
       "      <td>0.159091</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.265152</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.850376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>100</td>\n",
       "      <td>25.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.902378</td>\n",
       "      <td>0.158371</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.264151</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.850120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>100</td>\n",
       "      <td>30.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.902378</td>\n",
       "      <td>0.158371</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.264151</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.850120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     n_estimators  max_depth  min_samples  gral_accuracy  precision    recall  \\\n",
       "470            90       10.0          100       0.902879   0.159091  0.795455   \n",
       "550           100       25.0          100       0.902378   0.158371  0.795455   \n",
       "558           100       30.0          100       0.902378   0.158371  0.795455   \n",
       "\n",
       "     f1_score  support       auc  \n",
       "470  0.265152     88.0  0.850376  \n",
       "550  0.264151     88.0  0.850120  \n",
       "558  0.264151     88.0  0.850120  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_results[rf_results['recall'] > 0.75].sort_values(by='f1_score', ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this information we'll use Logistic Regression with SMOTE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
